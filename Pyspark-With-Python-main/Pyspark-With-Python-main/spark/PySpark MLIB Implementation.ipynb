{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "spark_path = '/Users/pradmishra/Downloads/spark-2.1.0-bin-hadoop2.7'\n",
    "os.environ['SPARK_HOME']= spark_path\n",
    "os.environ['HADOOP_HOME']=spark_path\n",
    "sys.path.append(spark_path+'/bin')\n",
    "sys.path.append(spark_path+'/python')\n",
    "sys.path.append(spark_path+'/python/pyspark')\n",
    "sys.path.append(spark_path+'/python/lib')\n",
    "sys.path.append(spark_path+'/python/lib/pyspark.zip')\n",
    "sys.path.append(spark_path+'/python/lib/py4j-0.10.4-src.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.1.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.14 (default, Dec  4 2017 15:36:09)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "# Configure the necessary Spark environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "pyspark_submit_args = os.environ.get(\"PYSPARK_SUBMIT_ARGS\", \"\")\n",
    "if not \"pyspark-shell\" in pyspark_submit_args: pyspark_submit_args += \" pyspark-shell\"\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = pyspark_submit_args\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "sys.path.insert(0, spark_home + \"/python\")\n",
    "\n",
    "# Add the py4j to the path.\n",
    "# You may need to change the version number to match your install\n",
    "sys.path.insert(0, os.path.join(spark_home, \"python/lib/py4j-0.10.4-src.zip\"))\n",
    "\n",
    "# Initialize PySpark\n",
    "exec(open(os.path.join(spark_home, \"python/pyspark/shell.py\")).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install py4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(master='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x103a37310>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "rdd = sc.parallelize([('X01','2014-02-13T12:36:14.899','2014-02-13T12:31:56.876','sip:4534454450'),\n",
    "                                    ('X02','2014-02-13T12:35:37.405','2014-02-13T12:32:13.321','sip:6413445440'),\n",
    "                                    ('X03','2014-02-13T12:36:03.825','2014-02-13T12:32:15.229','sip:4534437492'),\n",
    "                                    ('XO4','2014-02-13T12:37:05.460','2014-02-13T12:32:36.881','sip:6474454453'),\n",
    "                                    ('XO5','2014-02-13T12:36:52.721','2014-02-13T12:33:30.323','sip:8874458555')])\n",
    "schema = StructType([StructField('ID', StringType(), True),\n",
    "                     StructField('EndDateTime', StringType(), True),\n",
    "                     StructField('StartDateTime', StringType(), True)])\n",
    "df = sqlContext.createDataFrame(rdd, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ID: string, EndDateTime: string, StartDateTime: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()\n",
    "sc= SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CRIM=0.00632, ZN=18.0, INDUS=2.309999943, CHAS=0, NOX=0.537999988, RM=6.574999809, AGE=65.19999695, DIS=4.090000153, RAD=1, TAX=296, PT=15.30000019, B=396.8999939, LSTAT=4.980000019, MV=24.0),\n",
       " Row(CRIM=0.027310001, ZN=0.0, INDUS=7.070000172, CHAS=0, NOX=0.469000012, RM=6.421000004, AGE=78.90000153, DIS=4.967100143, RAD=2, TAX=242, PT=17.79999924, B=396.8999939, LSTAT=9.140000343, MV=21.60000038),\n",
       " Row(CRIM=0.02729, ZN=0.0, INDUS=7.070000172, CHAS=0, NOX=0.469000012, RM=7.184999943, AGE=61.09999847, DIS=4.967100143, RAD=2, TAX=242, PT=17.79999924, B=392.8299866, LSTAT=4.03000021, MV=34.70000076),\n",
       " Row(CRIM=0.032370001, ZN=0.0, INDUS=2.180000067, CHAS=0, NOX=0.458000004, RM=6.998000145, AGE=45.79999924, DIS=6.062200069, RAD=3, TAX=222, PT=18.70000076, B=394.6300049, LSTAT=2.940000057, MV=33.40000153),\n",
       " Row(CRIM=0.069049999, ZN=0.0, INDUS=2.180000067, CHAS=0, NOX=0.458000004, RM=7.146999836, AGE=54.20000076, DIS=6.062200069, RAD=3, TAX=222, PT=18.70000076, B=396.8999939, LSTAT=5.329999924, MV=36.20000076)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('/Users/pradmishra/Documents/boston.csv')\n",
    "house_df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[CRIM: double, ZN: double, INDUS: double, CHAS: int, NOX: double, RM: double, AGE: double, DIS: double, RAD: int, TAX: int, PT: double, B: double, LSTAT: double, MV: double]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CRIM: double (nullable = true)\n",
      " |-- ZN: double (nullable = true)\n",
      " |-- INDUS: double (nullable = true)\n",
      " |-- CHAS: integer (nullable = true)\n",
      " |-- NOX: double (nullable = true)\n",
      " |-- RM: double (nullable = true)\n",
      " |-- AGE: double (nullable = true)\n",
      " |-- DIS: double (nullable = true)\n",
      " |-- RAD: integer (nullable = true)\n",
      " |-- TAX: integer (nullable = true)\n",
      " |-- PT: double (nullable = true)\n",
      " |-- B: double (nullable = true)\n",
      " |-- LSTAT: double (nullable = true)\n",
      " |-- MV: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "house_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform descriptive analytics\n",
    "#!pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>506</td>\n",
       "      <td>3.6135235608162057</td>\n",
       "      <td>8.601545086715594</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>88.97619629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>506</td>\n",
       "      <td>11.363636363636363</td>\n",
       "      <td>23.32245299451514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>506</td>\n",
       "      <td>11.136778749531626</td>\n",
       "      <td>6.86035298095724</td>\n",
       "      <td>0.460000008</td>\n",
       "      <td>27.73999977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>506</td>\n",
       "      <td>0.0691699604743083</td>\n",
       "      <td>0.2539940413404101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>506</td>\n",
       "      <td>0.5546950602312246</td>\n",
       "      <td>0.1158776754570543</td>\n",
       "      <td>0.38499999</td>\n",
       "      <td>0.870999992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>506</td>\n",
       "      <td>6.28463438896641</td>\n",
       "      <td>0.7026171549511354</td>\n",
       "      <td>3.561000109</td>\n",
       "      <td>8.779999733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>506</td>\n",
       "      <td>68.57490120115612</td>\n",
       "      <td>28.148861532793276</td>\n",
       "      <td>2.900000095</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>506</td>\n",
       "      <td>3.7950426960059325</td>\n",
       "      <td>2.105710142043288</td>\n",
       "      <td>1.129600048</td>\n",
       "      <td>12.12650013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>506</td>\n",
       "      <td>9.549407114624506</td>\n",
       "      <td>8.707259384239366</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>506</td>\n",
       "      <td>408.2371541501976</td>\n",
       "      <td>168.53711605495903</td>\n",
       "      <td>187</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT</th>\n",
       "      <td>506</td>\n",
       "      <td>18.45553382776679</td>\n",
       "      <td>2.164945780039869</td>\n",
       "      <td>12.60000038</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>506</td>\n",
       "      <td>356.67402960597883</td>\n",
       "      <td>91.29486340272308</td>\n",
       "      <td>0.319999993</td>\n",
       "      <td>396.8999939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>506</td>\n",
       "      <td>12.653063233922925</td>\n",
       "      <td>7.141061500195388</td>\n",
       "      <td>1.730000019</td>\n",
       "      <td>37.97000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MV</th>\n",
       "      <td>506</td>\n",
       "      <td>22.53280636250988</td>\n",
       "      <td>9.197104107945272</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0                   1                   2            3  \\\n",
       "summary  count                mean              stddev          min   \n",
       "CRIM       506  3.6135235608162057   8.601545086715594      0.00632   \n",
       "ZN         506  11.363636363636363   23.32245299451514          0.0   \n",
       "INDUS      506  11.136778749531626    6.86035298095724  0.460000008   \n",
       "CHAS       506  0.0691699604743083  0.2539940413404101            0   \n",
       "NOX        506  0.5546950602312246  0.1158776754570543   0.38499999   \n",
       "RM         506    6.28463438896641  0.7026171549511354  3.561000109   \n",
       "AGE        506   68.57490120115612  28.148861532793276  2.900000095   \n",
       "DIS        506  3.7950426960059325   2.105710142043288  1.129600048   \n",
       "RAD        506   9.549407114624506   8.707259384239366            1   \n",
       "TAX        506   408.2371541501976  168.53711605495903          187   \n",
       "PT         506   18.45553382776679   2.164945780039869  12.60000038   \n",
       "B          506  356.67402960597883   91.29486340272308  0.319999993   \n",
       "LSTAT      506  12.653063233922925   7.141061500195388  1.730000019   \n",
       "MV         506   22.53280636250988   9.197104107945272          5.0   \n",
       "\n",
       "                   4  \n",
       "summary          max  \n",
       "CRIM     88.97619629  \n",
       "ZN             100.0  \n",
       "INDUS    27.73999977  \n",
       "CHAS               1  \n",
       "NOX      0.870999992  \n",
       "RM       8.779999733  \n",
       "AGE            100.0  \n",
       "DIS      12.12650013  \n",
       "RAD               24  \n",
       "TAX              711  \n",
       "PT              22.0  \n",
       "B        396.8999939  \n",
       "LSTAT    37.97000122  \n",
       "MV              50.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_df.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter matrix is a great way to roughly determine if we have a linear correlation between multiple independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "numeric_features = [t[0] for t in house_df.dtypes if t[1] == 'int' or t[1] == 'double']\n",
    "sampled_data = house_df.select(numeric_features).sample(False, 0.8).toPandas()\n",
    "axs = pd.scatter_matrix(sampled_data, figsize=(10, 10))\n",
    "n = len(sampled_data.columns)\n",
    "for i in range(n):\n",
    "    v = axs[i, 0]\n",
    "    v.yaxis.label.set_rotation(0)\n",
    "    v.yaxis.label.set_ha('right')\n",
    "    v.set_yticks(())\n",
    "    h = axs[n-1, i]\n",
    "    h.xaxis.label.set_rotation(90)\n",
    "    h.set_xticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Correlation to MV for ', 'CRIM', -0.3883046116575088)\n",
      "('Correlation to MV for ', 'ZN', 0.36044534463752903)\n",
      "('Correlation to MV for ', 'INDUS', -0.48372517128143383)\n",
      "('Correlation to MV for ', 'CHAS', 0.17526017775291847)\n",
      "('Correlation to MV for ', 'NOX', -0.4273207763683772)\n",
      "('Correlation to MV for ', 'RM', 0.695359937127267)\n",
      "('Correlation to MV for ', 'AGE', -0.37695456714288667)\n",
      "('Correlation to MV for ', 'DIS', 0.24992873873512172)\n",
      "('Correlation to MV for ', 'RAD', -0.3816262315669168)\n",
      "('Correlation to MV for ', 'TAX', -0.46853593528654536)\n",
      "('Correlation to MV for ', 'PT', -0.5077867038116085)\n",
      "('Correlation to MV for ', 'B', 0.3334608226834164)\n",
      "('Correlation to MV for ', 'LSTAT', -0.7376627294671615)\n",
      "('Correlation to MV for ', 'MV', 1.0)\n"
     ]
    }
   ],
   "source": [
    "import six\n",
    "for i in house_df.columns:\n",
    "    if not( isinstance(house_df.select(i).take(1)[0][0], six.string_types)):\n",
    "        print( \"Correlation to MV for \", i, house_df.stat.corr('MV',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|            features|         MV|\n",
      "+--------------------+-----------+\n",
      "|[0.00632,18.0,2.3...|       24.0|\n",
      "|[0.027310001,0.0,...|21.60000038|\n",
      "|[0.02729,0.0,7.07...|34.70000076|\n",
      "+--------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler(inputCols = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PT', 'B', 'LSTAT'], outputCol = 'features')\n",
    "vhouse_df = vectorAssembler.transform(house_df)\n",
    "vhouse_df = vhouse_df.select(['features', 'MV'])\n",
    "vhouse_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = vhouse_df.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.049687906711926716,0.005729138144892694,0.0,1.2930551983265361,-5.127862706125868,3.7946667898241113,0.0,-0.6235890579389267,0.012500702919514804,0.0,-0.7678424543743334,0.007914622611657924,-0.524573600080142]\n",
      "Intercept: 21.6469319588\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='MV', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_df)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.960349\n",
      "r2: 0.689697\n"
     ]
    }
   ],
   "source": [
    "#Summarize the model over the training set and print out some metrics:\n",
    "trainingSummary = lr_model.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|                MV|\n",
      "+-------+------------------+\n",
      "|  count|               340|\n",
      "|   mean|22.372647093376475|\n",
      "| stddev| 8.917818137541282|\n",
      "|    min|               5.0|\n",
      "|    max|              50.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------+--------------------+\n",
      "|        prediction|         MV|            features|\n",
      "+------------------+-----------+--------------------+\n",
      "|31.023967272205553|32.70000076|[0.01301,35.0,1.5...|\n",
      "| 36.85660935784797|       50.0|[0.01381,80.0,0.4...|\n",
      "|25.719303860488395|30.10000038|[0.01709,90.0,2.0...|\n",
      "|25.463692979697388|       33.0|[0.019509999,17.5...|\n",
      "|20.061573817818797|20.10000038|[0.019649999,80.0...|\n",
      "|37.694326498812316|       50.0|[0.020090001,95.0...|\n",
      "|27.236851147822602|23.89999962|[0.025429999,55.0...|\n",
      "|28.732248796121993|31.20000076|[0.03049,55.0,3.7...|\n",
      "| 31.24440925650234|34.90000153|[0.03359,75.0,2.9...|\n",
      "|29.542372859430287|       28.5|[0.035020001,80.0...|\n",
      "|25.227220988202323|24.79999924|[0.036589999,25.0...|\n",
      "|27.589869673450398|       28.0|[0.041129999,25.0...|\n",
      "| 31.08000952169187|30.29999924|[0.046659999,80.0...|\n",
      "|22.921544529947212|11.89999962|[0.04741,0.0,11.9...|\n",
      "|28.568646008585084|28.20000076|[0.049320001,33.0...|\n",
      "+------------------+-----------+--------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#make predictions\n",
    "lr_predictions = lr_model.transform(test_df)\n",
    "lr_predictions.select(\"prediction\",\"MV\",\"features\").show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.738979\n"
     ]
    }
   ],
   "source": [
    "#evaluate results\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"MV\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 4.97332\n"
     ]
    }
   ],
   "source": [
    "test_result = lr_model.evaluate(test_df)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numIterations: 11\n",
      "objectiveHistory: [0.49999999999999956, 0.4357753677704518, 0.25185366664668424, 0.22804458277677025, 0.19937888801402628, 0.19553404353871723, 0.1945958474105226, 0.1934565829277708, 0.19293755562375098, 0.19234933157374726, 0.19205062722890984]\n",
      "+-------------------+\n",
      "|          residuals|\n",
      "+-------------------+\n",
      "| -6.183854552431036|\n",
      "| 2.4785283655311474|\n",
      "| -4.968314429966092|\n",
      "|  6.291630586031637|\n",
      "| 1.9343180097566695|\n",
      "|  1.309551303217436|\n",
      "|-0.7331612773792031|\n",
      "|-2.2969128386984323|\n",
      "| 11.163504584036467|\n",
      "| 10.269145335110856|\n",
      "| 2.7824242630052503|\n",
      "|-2.3119245802313806|\n",
      "|-0.6783855132152041|\n",
      "| 7.1064695161425675|\n",
      "| 0.7324915885003307|\n",
      "| -9.751238887723392|\n",
      "|  3.939665407620687|\n",
      "|-3.6128501882489203|\n",
      "|  2.410630411400426|\n",
      "|-1.6637210062722616|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#we achieved worse RMSE and R squared on the test set.\n",
    "\n",
    "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "trainingSummary.residuals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------+--------------------+\n",
      "|        prediction|         MV|            features|\n",
      "+------------------+-----------+--------------------+\n",
      "| 37.77147779908827|       50.0|[0.01381,80.0,0.4...|\n",
      "| 25.65319880049389|30.10000038|[0.01709,90.0,2.0...|\n",
      "| 31.11112296372059|32.90000153|[0.01778,95.0,1.4...|\n",
      "| 26.05082059769446|23.10000038|[0.0187,85.0,4.15...|\n",
      "| 38.72157510322816|       50.0|[0.020090001,95.0...|\n",
      "|26.236732285628218|       16.5|[0.024979999,0.0,...|\n",
      "|  27.9457409166711|23.89999962|[0.025429999,55.0...|\n",
      "|20.231784941037567|       17.5|[0.031129999,0.0,...|\n",
      "|28.872751441743098|24.10000038|[0.034449998,82.5...|\n",
      "| 24.75384880004313|19.39999962|[0.03466,35.0,6.0...|\n",
      "|  36.1524494473268|45.40000153|[0.035780001,20.0...|\n",
      "| 29.49920138186634|       23.5|[0.035840001,80.0...|\n",
      "|26.015594237724947|24.79999924|[0.036589999,25.0...|\n",
      "| 27.56217628539805|       22.0|[0.03932,0.0,3.41...|\n",
      "|35.181479893967605|33.29999924|[0.040109999,80.0...|\n",
      "|24.793055190918338|19.39999962|[0.043790001,80.0...|\n",
      "|24.568151445062487|19.79999924|[0.04544,0.0,3.24...|\n",
      "|23.335562383314407|11.89999962|[0.04741,0.0,11.9...|\n",
      "|29.735596995645903|28.20000076|[0.049320001,33.0...|\n",
      "|23.567114498008507|22.20000076|[0.050829999,0.0,...|\n",
      "+------------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using our Linear Regression model to make some predictions\n",
    "predictions = lr_model.transform(test_df)\n",
    "predictions.select(\"prediction\",\"MV\",\"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor_4b16ae1397359c9e2b25"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = '\n",
    "                           MV')\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model on the training set\n",
    "dt_model = dt.fit(train_df)\n",
    "\n",
    "# make predictions on the test dataset\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "\n",
    "# evaluate the prediction and print RMSE\n",
    "dt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"MV\", predictionCol=\"prediction\", metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 4.00338\n"
     ]
    }
   ],
   "source": [
    "rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(13, {0: 0.0424, 4: 0.0059, 5: 0.3019, 7: 0.0823, 9: 0.0045, 10: 0.0304, 11: 0.005, 12: 0.5276})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Importance\n",
    "dt_model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CRIM=0.00632, ZN=18.0, INDUS=2.309999943, CHAS=0, NOX=0.537999988, RM=6.574999809, AGE=65.19999695, DIS=4.090000153, RAD=1, TAX=296, PT=15.30000019, B=396.8999939, LSTAT=4.980000019, MV=24.0),\n",
       " Row(CRIM=0.027310001, ZN=0.0, INDUS=7.070000172, CHAS=0, NOX=0.469000012, RM=6.421000004, AGE=78.90000153, DIS=4.967100143, RAD=2, TAX=242, PT=17.79999924, B=396.8999939, LSTAT=9.140000343, MV=21.60000038),\n",
       " Row(CRIM=0.02729, ZN=0.0, INDUS=7.070000172, CHAS=0, NOX=0.469000012, RM=7.184999943, AGE=61.09999847, DIS=4.967100143, RAD=2, TAX=242, PT=17.79999924, B=392.8299866, LSTAT=4.03000021, MV=34.70000076)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_df.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient-boosted tree regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------+--------------------+\n",
      "|        prediction|         MV|            features|\n",
      "+------------------+-----------+--------------------+\n",
      "|33.340501037360035|32.70000076|[0.01301,35.0,1.5...|\n",
      "|47.790157452082816|       50.0|[0.01381,80.0,0.4...|\n",
      "|29.230305993053125|30.10000038|[0.01709,90.0,2.0...|\n",
      "|  32.1976668947514|       33.0|[0.019509999,17.5...|\n",
      "| 19.20520401324379|20.10000038|[0.019649999,80.0...|\n",
      "+------------------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import library\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "# initialize the model and declare the features and the target column\n",
    "gbt = GBTRegressor(featuresCol = 'features', labelCol = 'MV', maxIter=10)\n",
    "\n",
    "# train model\n",
    "gbt_model = gbt.fit(train_df)\n",
    "\n",
    "# make predictions\n",
    "gbt_predictions = gbt_model.transform(test_df)\n",
    "\n",
    "# show actual and predicted columns with the features\n",
    "gbt_predictions.select('prediction', 'MV', 'features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 3.6736\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model and print RMSE\n",
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"MV\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# print RMSE\n",
    "rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient-boosted tree regression performed the best on our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
